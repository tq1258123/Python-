# Selenium + Chrome/PhantomJS爬取淘宝美食

---

## 流程框架

1. 搜索关键词
2. 分析页面并翻页
3. 分析提取商品内容
4. 存储到mongdb

用户名密码可以输入，但是滑块验证码过不了

```python
from selenium import webdriver
from selenium.common.exceptions import TimeoutException
from selenium.webdriver.common.by import By
from selenium.webdriver.support import expected_conditions as EC
from selenium.webdriver.support.wait import WebDriverWait
from urllib.parse import quote
from pyquery import PyQuery as pq
import time
from selenium.webdriver.common.action_chains import ActionChains


# 声明配置好的浏览器对象
browser = webdriver.Chrome()
# 等待反应（需要手动扫码登陆）
wait = WebDriverWait(browser, 20)
text = 'iPhoneXR'


def login_page():
    login_url = 'https://login.taobao.com/member/login.jhtml?'
    browser.get(login_url)
    browser.find_element_by_xpath('//*[@id="TPL_username_1"]').send_keys('我逗你玩哼')
    browser.find_element_by_xpath('//*[@id="TPL_password_1"]').send_keys('tq58215318123')
    browser.find_element_by_xpath('//*[@id="J_SubmitStatic"]').click()
    time.sleep(2)
    button = browser.find_element_by_xpath('//*[@id="J_SubmitStatic"]')
    ActionChains(browser).click_and_hold(on_element=button).perform()
    ActionChains(browser).move_to_element_with_offset(to_element=button, xoffset=100, yoffset=0).perform()
    

def index_page(page):
    '''
    获取索引页
    :param page:
    :return:
    '''
    print('正在爬取第', page,'页')
    try:
        # 网址url
        url = 'https://s.taobao.com/search?q='+ quote(text)
        browser.get(url)
        if page > 1:
            #找到最下面的页码标签
            input = wait.until(
                EC.presence_of_element_located((By.CSS_SELECTOR, '#mainsrp-pager div.form > input'))
            )
            submit = wait.until(
                EC.element_to_be_clickable((By.CSS_SELECTOR, '#mainsrp-pager div.form > span.btn.J_Submit'))
            )
            input.clear()
            input.send_keys(page)
            #模拟点击确认
            submit.click()
        # 找到每页数据的标签
        wait.until(
            EC.text_to_be_present_in_element((By.CSS_SELECTOR, '#mainsrp-pager li.item.active > span'), str(page))
        )
        wait.until(
            EC.presence_of_element_located((By.CSS_SELECTOR, '.m-itemlist .items .item'))
        )
        # 调用函数，获取数据
        get_products()
    except TimeoutException:
        index_page(page)


def get_products():
    '''
    提取商品数据
    :return:
    '''
    # page_source获取网页源代码
    html = browser.page_source
    doc = pq(html)
    items = doc('#mainsrp-itemlist .items .item').items()
    for item in items:
        # 数据存入字典
        product = {
            'image': item.find('.pic .img').attr('data-src'),
            'price': item.find('.price').text(),
            'deal': item.find('.deal-cnt').text(),
            'title': item.find('.title').text(),
            'shop': item.find('.shop').text(),
            'location': item.find('.location').text(),
        }
        print(product)
#主函数
def main():
    '''
    遍历每一页
    :return:
    '''
    for i in range(1, 101):
        index_page(i)
     #关闭浏览器
    browser.close()

if __name__ == '__main__':
    main()
```

