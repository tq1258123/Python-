# Requests+xpath爬取豆瓣电影top250

---

```python
import requests
from fake_useragent import UserAgent
from lxml import etree
import json
from multiprocessing import Pool

# 获取网页源代码
def get_page_code(url):
    response = requests.get(url, headers={'User-Agent': UserAgent().chrome})
    response.encoding = 'utf-8'
    if response.status_code == 200:
        return response.text

# 获取详细电影信息链接
def get_movie_url(page_code):
    e = etree.HTML(page_code)
    movie_urls = e.xpath('//div[@class="hd"]/a/@href')
    return movie_urls

# 获取电影信息
def get_movie_info(movie_urls):
    movie_infos = []
    for movie_url in movie_urls:
        response = requests.get(movie_url, headers={'User-Agent': UserAgent().chrome})
        e = etree.HTML(response.text)
        year = e.xpath('//div[@id="info"]/span[@property="v:initialReleaseDate"][1]/text()')
        name = e.xpath('//h1/span[1]/text()')
        score = e.xpath('//div[@typeof="v:Rating"]/strong/text()')
        img_url = e.xpath('//div[@id="mainpic"]/a/img/@src')
        movie_info = {
            'year': year,
            'name': name,
            'score': score,
            'img_url': img_url
        }
        movie_infos.append(movie_info)
    return movie_infos

# 保存电影信息
def save_info(movie_infos):
    for movie_info in movie_infos:
        with open('doubanTop250.txt', 'a', encoding='utf-8') as f:
            f.write(json.dumps(movie_info, ensure_ascii=False) + '\n')


def main(i):
    url = 'https://movie.douban.com/top250?start={}&filter='.format(i)
    page_code = get_page_code(url)
    movie_urls = get_movie_url(page_code)
    movie_infos = get_movie_info(movie_urls)
    save_info(movie_infos)


if __name__ == '__main__':
    pool = Pool()
    pool.map(main, [i * 25 for i in range(10)])
```

