# 爬虫常用库的安装

---

## 请求库的安装

爬虫可以简单分为几步：抓取页面、分析页面、获取数据和存储数据。在抓取页面的过程中，我们需要模拟浏览器向服务器发出请求，所以需要用到一些Python可来实现HTTP请求操作。以下库的安装尽量保持在使用vpn的情况下安装，不然可能会因为网络的问题无法安装成功。

### requests安装

`pip install requests`

### Selenium安装

Selenium是一个自动化测试工具，利用它我们可以驱动浏览器执行特定的动作，如点击、下拉等操作。对于一些JavaScript渲染的页面来说，这种抓取方式非常有效。

`pip install selenium`

### ChromeDriver安装

Selenium库的使用需要浏览器配合，我们使用chrome浏览器。下载完成后，把chromedriver.exe复制到anaconda对于python的Scripts目录下。

### PhantomJS安装

PhantomJS是一个无界面的、可脚本编程的Webkit浏览器引擎，它原生支持多种Web标准：DOM操作，CSS选择器，JSON，Canvas和SVG等。Selenium支持PhantomJS，这样在运行的时候就不会弹出一个浏览器。直接进入网站下载，再配置环境。

### aiohttp安装

之前介绍的requests库是一个阻塞式HTTP请求库，当我们发出一个请求后，程序会一直等待服务器响应，直到得到响应后，程序才会进行下一步处理。其实，这个过程比较耗费时间。如果程序可以在这个等待过程中做一些其他的事情，如进行请求的调度、响应的处理等，那么爬取效率一定会大大提高。

aiohttp就是这样一个提供异步Web服务的库，Python中加入async/await关键字，是的毁掉的写法更加直观和人性化。aiohttp的异步操作借助于async/await关键字的写法变得更加简洁，架构更加清晰，使用异步请求库进行数据抓取时，大大提高效率。

`pip install aiohttp`

`pip install cchardet aiodns`

## 解析库的安装

抓取网页代码后，下一步就是从网页中提取信息。提取信息的方式众多，可以使用正则，也可以使用各种库。

### lxml安装

lxml是Python的一个解析库，支持HTML和XML的解析，支持XPath解析方式，而且效率高。

`pip install lxml`

### Beautiful Soup安装

`pip install beautifulsoup4`

### pyquery安装

pyquery通用是一个强大的网页解析工具，它提供了和jQuery类似的语法来解析HTML文档，支持CSS选择器，使用方便。

`pip install pyquery`

### tesserocr安装

ORC，即Optical Character Recognition，光学字符识别，是指通过扫描字符，然后通过其形状将其翻译成电子文本的过程。对于图形验证码来说，他们都是一些不规则字符，这些字符确实是由字符稍加扭曲变换得到的内容。

`conda install -c simonflueckiger tesserocr`

## 数据库的安装

作为数据存储的重要部分，数据库通用是必不可少的，数据库可以分为关系型数据库和非关系型数据库。关系型数据库如SQLite、MySql、Oracle等，其数据库是以表的形式存储；非关系型数据库如MongoDB、Redis等，它们的存储形式是键值对，存储形式更加灵活。

具体安装见第四章。

## 使用Python操作数据库的库

### PyMySQL安装

`pip install pymysql`

### PyMongo安装

`pip install pymongo`

### redis-py安装

`pip install redis`

### RedisDump安装

1. 安装Ruby
2. `gem install redis-dump`

## Web库安装

### Flask安装

`pip install flask`

### Tornado安装

`pip install tornado`

## App爬取相关库的安装

跳过。。。。。。

## 爬虫框架的安装

### pyspider安装

`pip install pyspider -i http://pypi.souban.com/simple/ --trusted-host pypi.douban.com`

### Scrapy安装

`conda install Scrapy`

### scrapy-splash安装----涉及部署库

没安装好。。

### Scrapy-Redis安装

`pip install scrapy-redis`

## 部署相关库的安装--------有问题没完成

### Docker安装

### Scrapyd安装

### Scrapyd-client安装

### Scrapy API安装

### Scrapyrt安装

### Gerapy安装

