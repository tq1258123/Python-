# 爬虫基础

---

## HTTP基本原理

在本节中，我们会详细了解HTTP的基本原理，了解在浏览器中敲入URL到获取网页内容之间发生了什么。了解了这些内容，有助于我们进一步了解爬虫的基本原理。

### URI和URL

URI的全称为Uniform Resource Identifier，即统一资源标识符，URL的全称为Univeral Resource Locator，即统一资源定位符。URL是URI的子集。URI还包括一个子类叫做URN，它的全称为Universal Resource Name，即统一资源名称。URN只命名资源而不指定如何定位资源。但是目前的互联网中，URN用的很少，所有几乎所有的URI都是URL，一般的网页链接我们可以称为URL，也可以称为URI。

### 超文本

超文本，英文为hypertext，我们在浏览器里看到的网页就是抄完便捷性而成的，其页面源代码是一系列HTML代码，里面包含一系列标签。浏览器解析这些标签后，使形成了我们平常看到的网页，而网页的源代码HTML就可以称为超文本。

### HTTP和HTTPS

HTTP的全称是Hyper Text Transfer Protocol，中文叫做超文本传输协议。HTTPS的全称为Hyper Text Transfer Protocol over Secure Socket Layer，是以安全为目标的HTTP通道，简单讲是HTTP的安全版，即HTTP下加入SSL层，简称HTTPS。

### HTTP请求过程

![Request和Response](D:\repository\PythonNotes\images\Request和Response.png)

### 请求

请求，由客户端向服务端发出，可以分为4部分内容：请求方法，请求网址，请求头和请求体。

#### 请求方法

| 方法    | 描述                                             |
| ------- | ------------------------------------------------ |
| GET     | 请求页面，并返回页面内容                         |
| HEAD    | 返回请求头                                       |
| POST    | 用于提交表单或上传文件                           |
| PUT     | 从客户端向服务器传送的数据取代指定文档中的内容   |
| DELETE  | 删除指定页面                                     |
| CONNECT | 把服务器当做跳板，让服务器代替客户端访问其他网页 |
| OPTIONS | 允许客户端查看服务器的性能                       |
| TRACE   | 主要用于测试或诊断                               |

### 响应

#### 响应状态码

#### 响应头

#### 响应体

## 网页基础

用浏览器访问网站时，页面各不相同，我们需要了解网页的基本组成、结构和节点等内容。

### 网页的组成

网页可以分为三大部分——HTML、CSS和JavaScript。HTML(Hyper Text Markup Language)形成网页的架构，CSS(Cascading Style Sheets)使页面变得更为美观，JavaScript是用户与信息之间不只是一种浏览与显示关系，而是实现了一种实时、动态、交互的页面功能。

### 网页的结构

```html
<!DOCTYPE html>
<html lang="en">
<head>
    <meta charset="UTF-8">
    <title>This is a Demo</title>
</head>
<body>
<div id="container">
    <div class="wrapper">
    <h2 class="title">Hello World</h2>
    <p class="text">Hello, this is a paragraph.</p>
</div>
</div>
</body>
</html>
```

### 节点树及节点间的关系

在HTML中，所有标签定义的内容都是节点，他们构成了一个HTML DOM树。

![节点树及节点间的关系](D:\repository\PythonNotes\images\节点树及节点间的关系.png)

### CSS选择器用法

## 爬虫基本原理

我们可以把互联网比作一张大网，而爬虫便是在网上爬行的蜘蛛。把网的节点比作一个个网页，爬虫爬到这就相当于访问了该页面，获取了信息。可以把节点间的连线比作网页与网页之间的链接关系，这样蜘蛛通过一个节点后，可以顺着节点连线继续爬行到下一个节点，即通过一个网页继续获取后续的页面，这样整个网的节点便可以被蜘蛛全部爬行到，网站的数据就可以被抓去下来。

### 爬虫基本流程

#### 获取页面

#### 提取信息

#### 保存数据

#### 自动化程序

### 能抓怎样的数据

字符串，图片，视频和音频。

### JavaScript渲染页面

有时候，我们在用urllib或requests抓取页面时，得到的源代码实际和浏览器看到的不一样。这是一个非常常见的问题。现在越来越多的采用Ajax、前端模块化工具来构建，整个网络可能都是有JavaScript渲染出来的，因此，对于这样的情况，我们可以分析其后台Ajax接口，也可使用Selenium、Splash这样的库来实现模拟JavaScript渲染。

## 会话和Cookies

## 代理的基本原理

